"use client";

import { useEffect, useState, useRef } from "react";
import { useParams, useRouter } from "next/navigation";
import VideoPlayer from "@/components/VideoPlayer";
import ChatInterface from "@/components/ChatInterface";
import CorrectionFeedback from "@/components/CorrectionFeedback";
import { WebSocketClient } from "@/lib/websocket";
import { AudioRecorder } from "@/lib/audioRecorder";
import { Message, Correction } from "@/types";
import { Mic, MicOff, Home } from "lucide-react";

export default function LearningPage() {
  const params = useParams();
  const router = useRouter();
  const sessionId = params.sessionId as string;

  const [messages, setMessages] = useState<Message[]>([]);
  const [corrections, setCorrections] = useState<Correction[]>([]);
  const [betterExpression, setBetterExpression] = useState<string>();
  const [feedback, setFeedback] = useState<string>();
  const [currentVideoUrl, setCurrentVideoUrl] = useState<string>();
  const [isRecording, setIsRecording] = useState(false);
  const [isVideoLoading, setIsVideoLoading] = useState(false);
  const [currentTranscription, setCurrentTranscription] = useState<string>();
  const [pendingAudio, setPendingAudio] = useState<string>();
  const [hasUserInteracted, setHasUserInteracted] = useState(false);

  const wsClientRef = useRef<WebSocketClient>();
  const audioRecorderRef = useRef<AudioRecorder>();

  useEffect(() => {
    // Initialize WebSocket
    wsClientRef.current = new WebSocketClient(sessionId);
    wsClientRef.current.connect();

    wsClientRef.current.onMessage((message) => {
      if (message.type === "response") {
        const { text, audio, video_url } = message.data;

        if (text) {
          setMessages((prev) => [
            ...prev,
            {
              id: Date.now().toString(),
              role: "assistant",
              content: text,
              timestamp: new Date(),
              videoUrl: video_url,
            },
          ]);
          // If we receive a response, it implies video generation will start or has started.
          setIsVideoLoading(true);
        }

        if (video_url) {
          // This is the initial welcome message which might have a video URL.
          setCurrentVideoUrl(video_url);
          setIsVideoLoading(false);
        } else {
          // For regular responses, video is not immediately available.
          // We already set isVideoLoading to true, so we wait for the video_update message.
        }

        // Play audio if available
        if (audio) {
          playAudio(audio);
        }
      } else if (message.type === "transcription") {
        const { text } = message.data;
        if (text) {
          setCurrentTranscription(text);
          setMessages((prev) => [
            ...prev,
            {
              id: Date.now().toString(),
              role: "user",
              content: text,
              timestamp: new Date(),
            },
          ]);
        }
      } else if (message.type === "correction") {
        const {
          corrections: corr,
          better_expression,
          feedback: fb,
        } = message.data;

        if (corr) {
          setCorrections(corr);
        }
        if (better_expression) {
          setBetterExpression(better_expression);
        }
        if (fb) {
          setFeedback(fb);
        }
      } else if (message.type === "video_update") {
        const { text, video_url } = message.data;
        if (video_url) {
          setCurrentVideoUrl(video_url);
          // Find the corresponding message and update its videoUrl
          setMessages((prev) =>
            prev.map((msg) =>
              msg.content === text && msg.role === "assistant"
                ? { ...msg, videoUrl: video_url }
                : msg
            )
          );
        }
        // Video is ready, stop loading.
        setIsVideoLoading(false);
      } else if (message.type === "error") {
        const { message: errorMessage } = message.data;
        alert(`ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${errorMessage}`);
      }
    });

    // Initialize audio recorder
    audioRecorderRef.current = new AudioRecorder();

    return () => {
      wsClientRef.current?.disconnect();
    };
  }, [sessionId]);

  useEffect(() => {
    if (hasUserInteracted && pendingAudio) {
      playAudio(pendingAudio);
    }
  }, [hasUserInteracted, pendingAudio]);

  const playAudio = async (base64Audio: string) => {
    if (!hasUserInteracted) {
      // Queue the audio to play after user interaction
      setPendingAudio(base64Audio);
      return;
    }

    try {
      const audio = new Audio(`data:audio/mp3;base64,${base64Audio}`);
      await audio.play();
      setPendingAudio(undefined);
    } catch (error) {
      console.error("Failed to play audio:", error);
    }
  };

  const toggleRecording = async () => {
    if (!audioRecorderRef.current) return;

    if (isRecording) {
      // Stop recording
      try {
        const audioBase64 = await audioRecorderRef.current.stop();
        wsClientRef.current?.sendAudio(audioBase64);
        setIsRecording(false);
        setCurrentTranscription(undefined);
        setCorrections([]);
        setBetterExpression(undefined);
        setFeedback(undefined);
      } catch (error) {
        console.error("Failed to stop recording:", error);
      }
    } else {
      // Start recording
      try {
        setHasUserInteracted(true);
        await audioRecorderRef.current.start();
        setIsRecording(true);
      } catch (error) {
        console.error("Failed to start recording:", error);
        alert("ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.");
      }
    }
  };

  const endSession = async () => {
    try {
      await fetch(
        `${process.env.NEXT_PUBLIC_API_URL}/api/conversations/sessions/${sessionId}/end`,
        {
          method: "POST",
        }
      );
      router.push("/");
    } catch (error) {
      console.error("Failed to end session:", error);
    }
  };

  return (
    <div className="min-h-screen bg-gray-50 p-4">
      <div className="max-w-7xl mx-auto">
        {/* Header */}
        <div className="flex justify-between items-center mb-6">
          <h1 className="text-3xl font-bold text-gray-900">ì˜ì–´ í•™ìŠµ ì„¸ì…˜</h1>
          <button
            onClick={endSession}
            className="flex items-center space-x-2 px-4 py-2 bg-gray-200 hover:bg-gray-300 rounded-lg transition-colors"
          >
            <Home size={20} />
            <span>ì¢…ë£Œí•˜ê¸°</span>
          </button>
        </div>

        {pendingAudio && !hasUserInteracted && (
          <div className="mb-4 p-4 bg-yellow-50 border border-yellow-200 rounded-lg">
            <p className="text-yellow-800 text-center">
              ğŸ”Š ì˜¤ë””ì˜¤ê°€ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤. ë§ˆì´í¬ ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ì¬ìƒë©ë‹ˆë‹¤.
            </p>
          </div>
        )}

        <div className="grid grid-cols-1 lg:grid-cols-3 gap-6">
          {/* Left column - Video Player */}
          <div className="lg:col-span-2 space-y-6">
            <VideoPlayer
              videoUrl={currentVideoUrl}
              isLoading={isVideoLoading}
            />

            {/* Recording Controls */}
            <div className="bg-white rounded-lg shadow-lg p-6">
              <div className="flex flex-col items-center space-y-4">
                <button
                  onClick={toggleRecording}
                  className={`w-20 h-20 rounded-full flex items-center justify-center transition-all ${
                    isRecording
                      ? "bg-red-500 hover:bg-red-600 animate-pulse"
                      : "bg-blue-600 hover:bg-blue-700"
                  } text-white shadow-lg`}
                >
                  {isRecording ? <MicOff size={32} /> : <Mic size={32} />}
                </button>

                <div className="text-center">
                  <p className="text-lg font-semibold text-gray-900">
                    {isRecording ? "ë…¹ìŒ ì¤‘..." : "ë§í•˜ê¸° ì‹œì‘í•˜ë ¤ë©´ í´ë¦­"}
                  </p>
                  <p className="text-sm text-gray-500">
                    {isRecording
                      ? "ë‹¤ì‹œ í´ë¦­í•˜ë©´ ë…¹ìŒì´ ì¢…ë£Œë˜ê³  ë¶„ì„ì´ ì‹œì‘ë©ë‹ˆë‹¤"
                      : "ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”"}
                  </p>
                </div>

                {currentTranscription && (
                  <div className="w-full p-4 bg-blue-50 rounded-lg border border-blue-200">
                    <p className="text-sm text-gray-600 mb-1">ì¸ì‹ëœ ë‚´ìš©:</p>
                    <p className="text-lg text-gray-900">
                      {currentTranscription}
                    </p>
                  </div>
                )}
              </div>
            </div>

            {/* Chat Interface */}
            <ChatInterface messages={messages} />
          </div>

          {/* Right column - Feedback */}
          <div className="lg:col-span-1">
            <div className="bg-white rounded-lg shadow-lg p-6 sticky top-4">
              <CorrectionFeedback
                corrections={corrections}
                betterExpression={betterExpression}
                feedback={feedback}
              />

              {corrections.length === 0 && !feedback && (
                <div className="text-center text-gray-400 py-8">
                  <p className="text-4xl mb-4">âœ¨</p>
                  <p>í”¼ë“œë°±ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤</p>
                </div>
              )}
            </div>
          </div>
        </div>
      </div>
    </div>
  );
}
